{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "gHLnftNuI211",
        "outputId": "420a8666-6802-45d9-f22d-8be9fd2dd6b8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Accountant</td>\n",
              "      <td>education omba executive leadership university...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Accountant</td>\n",
              "      <td>howard gerrard accountant deyjobcom birmingham...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Accountant</td>\n",
              "      <td>kevin frank senior accountant inforesumekraftc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Accountant</td>\n",
              "      <td>place birth nationality olivia ogilvy accounta...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Accountant</td>\n",
              "      <td>stephen greet cpa senior accountant 9 year exp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13384</th>\n",
              "      <td>Web Designing</td>\n",
              "      <td>jessica claire montgomery street san francisco...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13385</th>\n",
              "      <td>Web Designing</td>\n",
              "      <td>jessica claire montgomery street san francisco...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13386</th>\n",
              "      <td>Web Designing</td>\n",
              "      <td>summary jessica claire 100 montgomery st 10th ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13387</th>\n",
              "      <td>Web Designing</td>\n",
              "      <td>jessica claire montgomery street san francisco...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13388</th>\n",
              "      <td>Web Designing</td>\n",
              "      <td>websites portfolios profiles professional summ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13389 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Category                                               Text\n",
              "0         Accountant  education omba executive leadership university...\n",
              "1         Accountant  howard gerrard accountant deyjobcom birmingham...\n",
              "2         Accountant  kevin frank senior accountant inforesumekraftc...\n",
              "3         Accountant  place birth nationality olivia ogilvy accounta...\n",
              "4         Accountant  stephen greet cpa senior accountant 9 year exp...\n",
              "...              ...                                                ...\n",
              "13384  Web Designing  jessica claire montgomery street san francisco...\n",
              "13385  Web Designing  jessica claire montgomery street san francisco...\n",
              "13386  Web Designing  summary jessica claire 100 montgomery st 10th ...\n",
              "13387  Web Designing  jessica claire montgomery street san francisco...\n",
              "13388  Web Designing  websites portfolios profiles professional summ...\n",
              "\n",
              "[13389 rows x 2 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('train.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**using specific numpy library because when i previously tried to import gensim the numpy version was causing the error it mentioned that the version isn't compatible and error suggested this version**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3s0t5gCWPd5l",
        "outputId": "083b65bc-fddb-4f16-f8f6-9fc20d8b1b9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp312-cp312-win_amd64.whl.metadata (8.2 kB)\n",
            "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
            "Collecting smart-open>=1.8.1 (from gensim)\n",
            "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: wrapt in c:\\users\\asus\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.17.0)\n",
            "Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
            "   ---------------------------------------- 0.0/15.5 MB ? eta -:--:--\n",
            "   ------ --------------------------------- 2.6/15.5 MB 18.9 MB/s eta 0:00:01\n",
            "   ---------- ----------------------------- 4.2/15.5 MB 16.8 MB/s eta 0:00:01\n",
            "   -------------- ------------------------- 5.5/15.5 MB 9.6 MB/s eta 0:00:02\n",
            "   ----------------- ---------------------- 6.8/15.5 MB 8.6 MB/s eta 0:00:02\n",
            "   ------------------- -------------------- 7.6/15.5 MB 7.8 MB/s eta 0:00:02\n",
            "   ---------------------- ----------------- 8.9/15.5 MB 7.2 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 10.0/15.5 MB 6.9 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 10.7/15.5 MB 6.6 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 12.1/15.5 MB 6.5 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 12.8/15.5 MB 6.3 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 13.9/15.5 MB 6.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------  15.2/15.5 MB 6.1 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 15.5/15.5 MB 6.0 MB/s eta 0:00:00\n",
            "Downloading gensim-4.3.3-cp312-cp312-win_amd64.whl (24.0 MB)\n",
            "   ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
            "   - -------------------------------------- 1.0/24.0 MB 6.3 MB/s eta 0:00:04\n",
            "   --- ------------------------------------ 1.8/24.0 MB 6.3 MB/s eta 0:00:04\n",
            "   --- ------------------------------------ 2.4/24.0 MB 3.7 MB/s eta 0:00:06\n",
            "   ------- -------------------------------- 4.5/24.0 MB 5.5 MB/s eta 0:00:04\n",
            "   --------- ------------------------------ 5.5/24.0 MB 5.3 MB/s eta 0:00:04\n",
            "   ---------- ----------------------------- 6.3/24.0 MB 5.1 MB/s eta 0:00:04\n",
            "   ------------ --------------------------- 7.3/24.0 MB 5.1 MB/s eta 0:00:04\n",
            "   ------------- -------------------------- 8.4/24.0 MB 5.1 MB/s eta 0:00:04\n",
            "   --------------- ------------------------ 9.4/24.0 MB 5.0 MB/s eta 0:00:03\n",
            "   ----------------- ---------------------- 10.2/24.0 MB 4.9 MB/s eta 0:00:03\n",
            "   ------------------ --------------------- 11.3/24.0 MB 4.9 MB/s eta 0:00:03\n",
            "   -------------------- ------------------- 12.3/24.0 MB 5.0 MB/s eta 0:00:03\n",
            "   ---------------------- ----------------- 13.6/24.0 MB 5.0 MB/s eta 0:00:03\n",
            "   ------------------------ --------------- 14.7/24.0 MB 5.0 MB/s eta 0:00:02\n",
            "   -------------------------- ------------- 15.7/24.0 MB 5.0 MB/s eta 0:00:02\n",
            "   --------------------------- ------------ 16.8/24.0 MB 5.0 MB/s eta 0:00:02\n",
            "   ----------------------------- ---------- 17.8/24.0 MB 5.0 MB/s eta 0:00:02\n",
            "   ------------------------------- -------- 18.9/24.0 MB 5.0 MB/s eta 0:00:02\n",
            "   -------------------------------- ------- 19.7/24.0 MB 5.0 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 20.7/24.0 MB 5.0 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 21.8/24.0 MB 5.0 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 23.1/24.0 MB 5.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------  23.9/24.0 MB 5.0 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 24.0/24.0 MB 4.9 MB/s eta 0:00:00\n",
            "Downloading scipy-1.13.1-cp312-cp312-win_amd64.whl (45.9 MB)\n",
            "   ---------------------------------------- 0.0/45.9 MB ? eta -:--:--\n",
            "    --------------------------------------- 1.0/45.9 MB 5.6 MB/s eta 0:00:08\n",
            "   - -------------------------------------- 2.1/45.9 MB 6.2 MB/s eta 0:00:08\n",
            "   -- ------------------------------------- 3.1/45.9 MB 6.2 MB/s eta 0:00:07\n",
            "   -- ------------------------------------- 3.1/45.9 MB 6.2 MB/s eta 0:00:07\n",
            "   ---- ----------------------------------- 5.5/45.9 MB 5.5 MB/s eta 0:00:08\n",
            "   ----- ---------------------------------- 6.6/45.9 MB 5.4 MB/s eta 0:00:08\n",
            "   ------ --------------------------------- 7.3/45.9 MB 5.3 MB/s eta 0:00:08\n",
            "   ------- -------------------------------- 8.4/45.9 MB 5.1 MB/s eta 0:00:08\n",
            "   -------- ------------------------------- 9.4/45.9 MB 5.1 MB/s eta 0:00:08\n",
            "   --------- ------------------------------ 10.5/45.9 MB 5.0 MB/s eta 0:00:08\n",
            "   --------- ------------------------------ 11.3/45.9 MB 5.0 MB/s eta 0:00:07\n",
            "   ---------- ----------------------------- 12.6/45.9 MB 5.0 MB/s eta 0:00:07\n",
            "   ------------ --------------------------- 13.9/45.9 MB 5.1 MB/s eta 0:00:07\n",
            "   ------------ --------------------------- 14.4/45.9 MB 5.0 MB/s eta 0:00:07\n",
            "   ------------- -------------------------- 16.0/45.9 MB 5.1 MB/s eta 0:00:06\n",
            "   -------------- ------------------------- 16.8/45.9 MB 5.0 MB/s eta 0:00:06\n",
            "   --------------- ------------------------ 17.8/45.9 MB 5.0 MB/s eta 0:00:06\n",
            "   ---------------- ----------------------- 18.9/45.9 MB 5.0 MB/s eta 0:00:06\n",
            "   ---------------- ----------------------- 19.1/45.9 MB 5.0 MB/s eta 0:00:06\n",
            "   ----------------- ---------------------- 19.9/45.9 MB 4.7 MB/s eta 0:00:06\n",
            "   ------------------ --------------------- 20.7/45.9 MB 4.7 MB/s eta 0:00:06\n",
            "   ------------------ --------------------- 21.8/45.9 MB 4.7 MB/s eta 0:00:06\n",
            "   ------------------- -------------------- 22.8/45.9 MB 4.8 MB/s eta 0:00:05\n",
            "   --------------------- ------------------ 24.1/45.9 MB 4.8 MB/s eta 0:00:05\n",
            "   ---------------------- ----------------- 25.7/45.9 MB 4.9 MB/s eta 0:00:05\n",
            "   ----------------------- ---------------- 26.7/45.9 MB 5.0 MB/s eta 0:00:04\n",
            "   ------------------------ --------------- 28.3/45.9 MB 5.0 MB/s eta 0:00:04\n",
            "   ------------------------- -------------- 29.1/45.9 MB 5.0 MB/s eta 0:00:04\n",
            "   -------------------------- ------------- 30.1/45.9 MB 5.0 MB/s eta 0:00:04\n",
            "   --------------------------- ------------ 31.2/45.9 MB 4.9 MB/s eta 0:00:03\n",
            "   --------------------------- ------------ 32.0/45.9 MB 5.0 MB/s eta 0:00:03\n",
            "   ---------------------------- ----------- 33.0/45.9 MB 4.9 MB/s eta 0:00:03\n",
            "   ----------------------------- ---------- 34.1/45.9 MB 4.9 MB/s eta 0:00:03\n",
            "   ------------------------------ --------- 34.9/45.9 MB 4.9 MB/s eta 0:00:03\n",
            "   ------------------------------- -------- 36.2/45.9 MB 4.9 MB/s eta 0:00:02\n",
            "   -------------------------------- ------- 37.5/45.9 MB 5.0 MB/s eta 0:00:02\n",
            "   --------------------------------- ------ 38.3/45.9 MB 4.9 MB/s eta 0:00:02\n",
            "   ---------------------------------- ----- 39.6/45.9 MB 5.0 MB/s eta 0:00:02\n",
            "   ----------------------------------- ---- 40.6/45.9 MB 4.9 MB/s eta 0:00:02\n",
            "   ------------------------------------ --- 41.7/45.9 MB 4.9 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 42.5/45.9 MB 4.9 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 43.5/45.9 MB 4.9 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 44.6/45.9 MB 4.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------  45.6/45.9 MB 4.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 45.9/45.9 MB 4.9 MB/s eta 0:00:00\n",
            "Downloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
            "Installing collected packages: smart-open, numpy, scipy, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.14.1\n",
            "    Uninstalling scipy-1.14.1:\n",
            "      Successfully uninstalled scipy-1.14.1\n",
            "Successfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1 smart-open-7.1.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\~umpy.libs'.\n",
            "  You can safely remove it manually.\n",
            "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\~umpy'.\n",
            "  You can safely remove it manually.\n",
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade numpy==1.26.4 gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wcwjwk-EQAc1"
      },
      "outputs": [],
      "source": [
        "import gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loading Pre-trained Word2Vec Embeddings\n",
        "\n",
        "loading the pre-trained Word2Vec model `word2vec-google-news-300` from the `gensim` library’s dataset API.  \n",
        "This model contains 300-dimensional embeddings trained on Google News data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2TIMsuvQFmg",
        "outputId": "0804cb50-931e-44c6-d787-e713ebcce77a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader as api\n",
        "word2vec = api.load('word2vec-google-news-300')\n",
        "embedding_dim = word2vec.vector_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v0IBR84Qq8r",
        "outputId": "14c1c4a7-84c6-4836-cf0e-dcee8d1df2f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "300\n"
          ]
        }
      ],
      "source": [
        "print(embedding_dim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "YBWwlV1_75ZH"
      },
      "outputs": [],
      "source": [
        "embed_dim = 300\n",
        "num_heads = 4\n",
        "ff_hidden_dim = 256\n",
        "num_classes = 43\n",
        "num_layers = 2\n",
        "max_len = 100\n",
        "num_epochs = 12\n",
        "batch_size = 32\n",
        "learning_rate = 5e-4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tokenizing Text and Converting to Embeddings\n",
        "\n",
        "- `tokenize(text)`: Converts the input text to lowercase and splits it into words (tokens).\n",
        "- `text_to_embedding(text, word2vec, max_len)`:  \n",
        "  This converts a given text into a fixed-length sequence of word vectors using the pre-trained Word2Vec embeddings.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "W6YojY9VYN4w"
      },
      "outputs": [],
      "source": [
        "def tokenize(text):\n",
        "    return text.lower().split()\n",
        "\n",
        "def text_to_embedding(text, word2vec, max_len):\n",
        "    tokens = tokenize(text)\n",
        "    vectors = []\n",
        "    for token in tokens:\n",
        "        if token in word2vec:\n",
        "            vectors.append(word2vec[token])\n",
        "        else:\n",
        "            vectors.append(np.zeros(embedding_dim))\n",
        "    if len(vectors) < max_len:\n",
        "        vectors += [np.zeros(embedding_dim)] * (max_len - len(vectors))\n",
        "    else:\n",
        "        vectors = vectors[:max_len]\n",
        "    return np.array(vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "UXqSl50vYSQz"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import math\n",
        "import torch.nn as nn\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=512):\n",
        "        super().__init__()\n",
        "\n",
        "        # Create a matrix of shape (max_len, d_model) filled with zeros\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "\n",
        "        # Create a tensor with position indices (0, 1, 2, ..., max_len-1)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "\n",
        "        # Compute the division term (different frequencies for each dimension)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        # Apply sin to even indices in the embedding dimension\n",
        "        for i in range(0, d_model, 2):\n",
        "            pe[:, i] = torch.sin(position[:, 0] * div_term[i // 2])\n",
        "\n",
        "        # Apply cos to odd indices in the embedding dimension\n",
        "        for i in range(1, d_model, 2):\n",
        "            pe[:, i] = torch.cos(position[:, 0] * div_term[i // 2])\n",
        "\n",
        "        # Add an extra batch dimension for broadcasting during addition\n",
        "        self.pe = pe.unsqueeze(0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Add positional encoding to the input embeddings\n",
        "        x = x + self.pe[:, :x.size(1)].to(x.device)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "HaQc9S_FcqxD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "class MultiHeadSelfAttention(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads):\n",
        "        super().__init__()\n",
        "\n",
        "        # Make sure embed_dim is divisible by num_heads\n",
        "        assert embed_dim % num_heads == 0\n",
        "\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = embed_dim // num_heads\n",
        "\n",
        "        # Linear layer to project input into Q, K, and V\n",
        "        self.qkv_proj = nn.Linear(embed_dim, embed_dim * 3)\n",
        "\n",
        "        # Linear layer to project concatenated head outputs back to embed_dim\n",
        "        self.out_proj = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, embed_dim = x.size()\n",
        "\n",
        "        # Project input into Q, K, V\n",
        "        # Output shape: (batch_size, seq_len, embed_dim * 3)\n",
        "        qkv = self.qkv_proj(x)\n",
        "\n",
        "        # Split into 3 parts along the last dimension (Q, K, V)\n",
        "        qkv = qkv.reshape(batch_size, seq_len, 3, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Rearrange dimensions for attention computation\n",
        "        # Shape: (3, batch_size, num_heads, seq_len, head_dim)\n",
        "        qkv = qkv.permute(2, 0, 3, 1, 4)\n",
        "\n",
        "        # Unpack into Q, K, V\n",
        "        Q, K, V = qkv[0], qkv[1], qkv[2]\n",
        "\n",
        "        # Compute scaled dot-product attention scores\n",
        "        # Shape: (batch_size, num_heads, seq_len, seq_len)\n",
        "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
        "\n",
        "        attn_weights = F.softmax(attn_scores, dim=-1)\n",
        "\n",
        "        attn_output = torch.matmul(attn_weights, V)\n",
        "        attn_output = attn_output.permute(0, 2, 1, 3)\n",
        "        attn_output = attn_output.reshape(batch_size, seq_len, embed_dim)\n",
        "\n",
        "        output = self.out_proj(attn_output)\n",
        "\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGULx1QxctHU"
      },
      "source": [
        "**Why permute to (2, 0, 3, 1, 4) and then later to something else?**\n",
        "\n",
        "\n",
        "1.   First permute:\n",
        "```python\n",
        "qkv = qkv.permute(2, 0, 3, 1, 4)\n",
        "```\n",
        "- From `(batch_size, seq_len, 3, num_heads, head_dim)` to `(3, batch_size, num_heads, seq_len, head_dim)`\n",
        "\n",
        "- Allows separating Q, K, V by indexing along first dimension\n",
        "2.   Later permute:\n",
        "```python\n",
        "attn_output = attn_output.permute(0, 2, 1, 3)\n",
        "```\n",
        "- After attention calculation, `attn_output` shape is `(batch_size, num_heads, seq_len, head_dim)`\n",
        "\n",
        "- This permutes to `(batch_size, seq_len, num_heads, head_dim)` for concatenating heads along the embedding dimension\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Transformer Block\n",
        "\n",
        "This defines a single encoder block of a Transformer model. It has:\n",
        "\n",
        "- **Multi-head self-attention:** To let the model focus on different parts of the input sequence simultaneously.\n",
        "- **Layer normalization:** Applied after adding the attention output back to the input (residual connection).\n",
        "- **Feedforward network:** A two-layer fully connected network with ReLU activation in between.\n",
        "- **Second layer normalization:** After adding the feedforward output back (another residual connection).\n",
        "- **Dropout:** Applied after attention and feedforward to reduce overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Rf1SLkhdgPjL"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, ff_hidden_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        # Multi-head attention\n",
        "        self.attention = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
        "\n",
        "        # Feed-forward network\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(embed_dim, ff_hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(ff_hidden_dim, embed_dim)\n",
        "        )\n",
        "\n",
        "        # LayerNorm for stability\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Multi-head Attention with residual connection\n",
        "        attn_output, _ = self.attention(x, x, x)\n",
        "        x = self.norm1(x + attn_output)\n",
        "\n",
        "        # Feed-forward network with residual connection\n",
        "        ff_output = self.ff(x)\n",
        "        x = self.norm2(x + ff_output)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Transformer Classifier Model\n",
        "\n",
        "This class builds a Transformer-based text classifier with the following parts:\n",
        "\n",
        "- **Positional Encoding:** Adds position information to the input embeddings so the model knows the order of tokens.\n",
        "- **Multiple Transformer Blocks:** A stack of Transformer encoder blocks (defined earlier) to process the input sequence.\n",
        "- **Global Average Pooling:** Averages the output embeddings across all tokens to get a single vector representing the whole input.\n",
        "- **Dropout:** Applied before the classifier to reduce overfitting.\n",
        "- **Classification Layer:** A linear layer that outputs logits for each class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCmx4xrsjBs3"
      },
      "outputs": [],
      "source": [
        "class TransformerClassifier(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, ff_hidden_dim, num_classes, num_layers, max_len):\n",
        "        super().__init__()\n",
        "\n",
        "        # Positional encoding\n",
        "        self.pos_encoder = PositionalEncoding(embed_dim, max_len)\n",
        "\n",
        "        # Stack multiple Transformer blocks\n",
        "        self.layers = nn.ModuleList([\n",
        "            TransformerBlock(embed_dim, num_heads, ff_hidden_dim)\n",
        "            for _ in range(num_layers)\n",
        "        ])\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        # Final classification layer\n",
        "        self.classifier = nn.Linear(embed_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # 1️⃣ Add positional encoding\n",
        "        x = self.pos_encoder(x)\n",
        "\n",
        "        # 2️⃣ Pass through each Transformer block\n",
        "        for layer in self.layers:\n",
        "            x = layer(x)\n",
        "\n",
        "        # 3️⃣ Global average pooling over sequence dimension (dim=1)\n",
        "        x = x.mean(dim=1)\n",
        "        x = self.dropout(x)\n",
        "        logits = self.classifier(x)\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHtBif6bjkGU",
        "outputId": "56388af2-051b-4876-f958-239733406870"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Label Encoding Mapping:\n",
            "Accountant → 0\n",
            "Advocate → 1\n",
            "Agriculture → 2\n",
            "Apparel → 3\n",
            "Architecture → 4\n",
            "Arts → 5\n",
            "Automobile → 6\n",
            "Aviation → 7\n",
            "BPO → 8\n",
            "Banking → 9\n",
            "Blockchain → 10\n",
            "Building and Construction → 11\n",
            "Business Analyst → 12\n",
            "Civil Engineer → 13\n",
            "Consultant → 14\n",
            "Data Science → 15\n",
            "Database → 16\n",
            "Designing → 17\n",
            "DevOps → 18\n",
            "Digital Media → 19\n",
            "DotNet Developer → 20\n",
            "ETL Developer → 21\n",
            "Education → 22\n",
            "Electrical Engineering → 23\n",
            "Finance → 24\n",
            "Food and Beverages → 25\n",
            "Health and Fitness → 26\n",
            "Human Resources → 27\n",
            "Information Technology → 28\n",
            "Java Developer → 29\n",
            "Management → 30\n",
            "Mechanical Engineer → 31\n",
            "Network Security Engineer → 32\n",
            "Operations Manager → 33\n",
            "PMO → 34\n",
            "Public Relations → 35\n",
            "Python Developer → 36\n",
            "React Developer → 37\n",
            "SAP Developer → 38\n",
            "SQL Developer → 39\n",
            "Sales → 40\n",
            "Testing → 41\n",
            "Web Designing → 42\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "df['label'] = label_encoder.fit_transform(df['Category'])\n",
        "\n",
        "print(\"\\nLabel Encoding Mapping:\")\n",
        "for i, category in enumerate(label_encoder.classes_):\n",
        "    print(f\"{category} → {i}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "arS5m66Mlct7",
        "outputId": "5a4bca9b-7564-42f1-cc4c-d5349714c974"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Category</th>\n",
              "      <th>Text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Accountant</td>\n",
              "      <td>education omba executive leadership university...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Accountant</td>\n",
              "      <td>howard gerrard accountant deyjobcom birmingham...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Accountant</td>\n",
              "      <td>kevin frank senior accountant inforesumekraftc...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Accountant</td>\n",
              "      <td>place birth nationality olivia ogilvy accounta...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Accountant</td>\n",
              "      <td>stephen greet cpa senior accountant 9 year exp...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Category                                               Text  label\n",
              "0  Accountant  education omba executive leadership university...      0\n",
              "1  Accountant  howard gerrard accountant deyjobcom birmingham...      0\n",
              "2  Accountant  kevin frank senior accountant inforesumekraftc...      0\n",
              "3  Accountant  place birth nationality olivia ogilvy accounta...      0\n",
              "4  Accountant  stephen greet cpa senior accountant 9 year exp...      0"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goblPeLRliiv",
        "outputId": "abdddf01-508c-4f65-fca0-6409aa8d4031"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training set shape: (10711, 3)\n",
            "Validation set shape: (2678, 3)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Split the data (80% train, 20% validation)\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"\\nTraining set shape: {train_df.shape}\")\n",
        "print(f\"Validation set shape: {val_df.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4oPH8a7ElqrP"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# train_labels_tensor = torch.tensor(train_df['label'].values, dtype=torch.long)\n",
        "# val_labels_tensor = torch.tensor(val_df['label'].values, dtype=torch.long)\n",
        "\n",
        "# train_embeddings_tensor = torch.randn(len(train_df), max_len, embed_dim)\n",
        "# val_embeddings_tensor = torch.randn(len(val_df), max_len, embed_dim)\n",
        "\n",
        "# train_dataset = TensorDataset(train_embeddings_tensor, train_labels_tensor)\n",
        "# val_dataset = TensorDataset(val_embeddings_tensor, val_labels_tensor)\n",
        "\n",
        "# train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "# val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "train_embeddings_tensor = torch.randn(len(train_df), max_len, embed_dim)\n",
        "val_embeddings_tensor = torch.randn(len(val_df), max_len, embed_dim)\n",
        "```\n",
        "this was the error in the code because of which aggressive overfitting was happening\n",
        "\n",
        "**in the last I have trained model with error solved**\n",
        "> Lets fix this\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "def texts_to_tensor(texts, word2vec, max_len, embed_dim):\n",
        "    embeddings = []\n",
        "    for text in texts:\n",
        "        emb = text_to_embedding(text, word2vec, max_len)\n",
        "        embeddings.append(emb)\n",
        "    return torch.tensor(np.array(embeddings), dtype=torch.float32)\n",
        "\n",
        "train_embeddings_tensor = texts_to_tensor(train_df['Text'], word2vec, max_len, embed_dim)\n",
        "val_embeddings_tensor = texts_to_tensor(val_df['Text'], word2vec, max_len, embed_dim)\n",
        "\n",
        "train_labels_tensor = torch.tensor(train_df['label'].values, dtype=torch.long)\n",
        "val_labels_tensor = torch.tensor(val_df['label'].values, dtype=torch.long)\n",
        "\n",
        "train_dataset = TensorDataset(train_embeddings_tensor, train_labels_tensor)\n",
        "val_dataset = TensorDataset(val_embeddings_tensor, val_labels_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "LliML_R_nD2S"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "model = TransformerClassifier(embed_dim, num_heads, ff_hidden_dim, num_classes, num_layers, max_len)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "Wz8rcDzaoUa_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=10):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
        "        for inputs, labels in loop:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            acc = accuracy_score(all_labels, all_preds)\n",
        "            loop.set_postfix(loss=running_loss / len(all_labels), accuracy=acc)\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_acc = accuracy_score(all_labels, all_preds)\n",
        "\n",
        "        precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted' , zero_division=0)\n",
        "\n",
        "        print(f\"\\nEpoch {epoch+1} Train Loss: {epoch_loss:.4f} Acc: {accuracy_score(all_labels, all_preds)*100:.2f}% Precision: {precision*100:.2f} Recall: {recall*100:.2f} F1: {f1*100:.2f}\")\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_preds = []\n",
        "        val_labels = []\n",
        "        val_loss = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            loop = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\", leave=False)\n",
        "            for inputs, labels in loop:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "                preds = torch.argmax(outputs, dim=1)\n",
        "                val_preds.extend(preds.cpu().numpy())\n",
        "                val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "                val_acc = accuracy_score(val_labels, val_preds)\n",
        "                loop.set_postfix(val_loss=val_loss / len(val_labels), val_acc=val_acc)\n",
        "\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        val_acc = accuracy_score(val_labels, val_preds)\n",
        "        val_precision, val_recall, val_f1, _ = precision_recall_fscore_support(val_labels, val_preds, average='weighted' , zero_division=0)\n",
        "\n",
        "        print(f\"Epoch {epoch+1} Val Loss: {val_loss:.4f} Val Acc: {val_acc*100:.2f}% Val Precision: {val_precision*100:.2f} Val Recall: {val_recall*100:.2f} Val F1: {val_f1*100:.2f}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_NxXd4gxZbZ"
      },
      "outputs": [],
      "source": [
        "# train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=10)\n",
        "# parameters:-\n",
        "# embed_dim = 300\n",
        "# num_heads = 6\n",
        "# ff_hidden_dim = 512\n",
        "# num_classes = 43\n",
        "# num_layers = 2\n",
        "# max_len = 100\n",
        "# num_epochs = 8\n",
        "# batch_size = 64\n",
        "# learning_rate = 1e-4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WYrujJurW0-"
      },
      "source": [
        "**I stopped the training as model was aggressively overfitting (i lost the cell output so just wrote in markdown)**\n",
        "\n",
        " Epoch 1/10 [Train]: 100%|██████████| 335/335 [02:22<00:00,  2.35it/s, accuracy=0.0298, loss=3.74]\n",
        "\n",
        "Epoch 1 Train Loss: 3.7395 Acc: 2.98% Precision: 3.91 Recall: 2.98 F1: 1.92\n",
        "Epoch 1 Val Loss: 3.7528 Val Acc: 2.46% Val Precision: 0.10 Val Recall: 2.46 Val F1: 0.20\n",
        "\n",
        "Epoch 2/10 [Train]: 100%|██████████| 335/335 [02:24<00:00,  2.32it/s, accuracy=0.0389, loss=3.72]\n",
        "\n",
        "Epoch 2 Train Loss: 3.7174 Acc: 3.89% Precision: 3.16 Recall: 3.89 F1: 2.78\n",
        "Epoch 2 Val Loss: 3.7482 Val Acc: 2.28% Val Precision: 0.62 Val Recall: 2.28 Val F1: 0.70\n",
        "\n",
        "Epoch 3/10 [Train]: 100%|██████████| 335/335 [02:21<00:00,  2.36it/s, accuracy=0.0615, loss=3.65]\n",
        "\n",
        "Epoch 3 Train Loss: 3.6545 Acc: 6.15% Precision: 6.40 Recall: 6.15 F1: 5.02\n",
        "Epoch 3 Val Loss: 3.7766 Val Acc: 2.73% Val Precision: 4.26 Val Recall: 2.73 Val F1: 1.40\n",
        "\n",
        "Epoch 4/10 [Train]: 100%|██████████| 335/335 [02:22<00:00,  2.35it/s, accuracy=0.113, loss=3.49]\n",
        "\n",
        "Epoch 4 Train Loss: 3.4859 Acc: 11.25% Precision: 12.16 Recall: 11.25 F1: 10.21\n",
        "Epoch 4 Val Loss: 3.8425 Val Acc: 2.35% Val Precision: 2.86 Val Recall: 2.35 Val F1: 1.86\n",
        "\n",
        "Epoch 5/10 [Train]: 100%|██████████| 335/335 [02:21<00:00,  2.38it/s, accuracy=0.202, loss=3.17]\n",
        "\n",
        "Epoch 5 Train Loss: 3.1654 Acc: 20.17% Precision: 21.32 Recall: 20.17 F1: 19.18\n",
        "Epoch 5 Val Loss: 4.0261 Val Acc: 2.65% Val Precision: 2.96 Val Recall: 2.65 Val F1: 2.03\n",
        "\n",
        "Epoch 6/10 [Train]: 100%|██████████| 335/335 [02:21<00:00,  2.36it/s, accuracy=0.307, loss=2.71]\n",
        "\n",
        "Epoch 6 Train Loss: 2.7085 Acc: 30.73% Precision: 31.46 Recall: 30.73 F1: 29.94\n",
        "Epoch 6 Val Loss: 4.3188 Val Acc: 2.46% Val Precision: 2.52 Val Recall: 2.46 Val F1: 2.20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "id": "fIaxbad3pwH9",
        "outputId": "5b82b32a-c758-49f4-eed2-72198d8cd550"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 [Train]: 100%|██████████| 335/335 [01:52<00:00,  2.97it/s, accuracy=0.0254, loss=3.78]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1 Train Loss: 3.7806 Acc: 2.54% Precision: 1.64 Recall: 2.54 F1: 1.83\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Val Loss: 3.7654 Val Acc: 2.73% Val Precision: 0.20 Val Recall: 2.73 Val F1: 0.38\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 [Train]: 100%|██████████| 335/335 [01:48<00:00,  3.09it/s, accuracy=0.0252, loss=3.76]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2 Train Loss: 3.7605 Acc: 2.52% Precision: 1.85 Recall: 2.52 F1: 1.88\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 Val Loss: 3.7538 Val Acc: 3.02% Val Precision: 0.93 Val Recall: 3.02 Val F1: 1.12\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 [Train]: 100%|██████████| 335/335 [01:46<00:00,  3.14it/s, accuracy=0.0372, loss=3.73]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3 Train Loss: 3.7261 Acc: 3.72% Precision: 3.95 Recall: 3.72 F1: 3.08\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 Val Loss: 3.7863 Val Acc: 2.69% Val Precision: 1.39 Val Recall: 2.69 Val F1: 0.93\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 [Train]: 100%|██████████| 335/335 [01:48<00:00,  3.09it/s, accuracy=0.0598, loss=3.65]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4 Train Loss: 3.6520 Acc: 5.98% Precision: 6.00 Recall: 5.98 F1: 5.55\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 Val Loss: 3.8272 Val Acc: 2.20% Val Precision: 2.72 Val Recall: 2.20 Val F1: 1.54\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 [Train]: 100%|██████████| 335/335 [01:48<00:00,  3.09it/s, accuracy=0.0871, loss=3.52]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5 Train Loss: 3.5217 Acc: 8.71% Precision: 8.64 Recall: 8.71 F1: 8.31\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 Val Loss: 3.9441 Val Acc: 1.87% Val Precision: 2.70 Val Recall: 1.87 Val F1: 1.57\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 [Train]:   7%|▋         | 24/335 [00:08<01:44,  2.99it/s, accuracy=0.176, loss=3.24]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-c3b017988b13>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-43-74bde50593c4>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, device, num_epochs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#training -2\n",
        "#parameter:-\n",
        "# embed_dim = 300\n",
        "# num_heads = 2\n",
        "# ff_hidden_dim = 128\n",
        "# num_classes = 43\n",
        "# num_layers = 1\n",
        "# max_len = 200\n",
        "# num_epochs = 8\n",
        "# batch_size = 32\n",
        "# learning_rate = 1e-3\n",
        "train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=10) #less epoch to check overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2595arhT2nny"
      },
      "source": [
        "**Again Overfitting**\n",
        "\n",
        "\n",
        "\n",
        "> Lets use LR Scheduler\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "87FHDRDuwYBW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "def train_model_new(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=10, patience=2):\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)\n",
        "    best_val_loss = np.inf\n",
        "    best_val_f1 = 0\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
        "        for inputs, labels in loop:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            \n",
        "            loop.set_postfix(loss=running_loss/len(all_labels))\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_acc = accuracy_score(all_labels, all_preds)\n",
        "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "            all_labels, all_preds, average='weighted', zero_division=0\n",
        "        )\n",
        "\n",
        "        print(f\"\\nEpoch {epoch+1} Train Loss: {epoch_loss:.4f} Acc: {epoch_acc*100:.2f}% \"\n",
        "              f\"Precision: {precision*100:.2f} Recall: {recall*100:.2f} F1: {f1*100:.2f}\")\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_preds = []\n",
        "        val_labels = []\n",
        "        val_loss = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            loop = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\", leave=False)\n",
        "            for inputs, labels in loop:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "                preds = torch.argmax(outputs, dim=1)\n",
        "                val_preds.extend(preds.cpu().numpy())\n",
        "                val_labels.extend(labels.cpu().numpy())\n",
        "                \n",
        "                loop.set_postfix(val_loss=val_loss/len(val_labels))\n",
        "\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        val_acc = accuracy_score(val_labels, val_preds)\n",
        "        val_precision, val_recall, val_f1, _ = precision_recall_fscore_support(\n",
        "            val_labels, val_preds, average='weighted', zero_division=0\n",
        "        )\n",
        "\n",
        "        print(f\"Epoch {epoch+1} Val Loss: {val_loss:.4f} Val Acc: {val_acc*100:.2f}% \"\n",
        "              f\"Val Precision: {val_precision*100:.2f} Val Recall: {val_recall*100:.2f} Val F1: {val_f1*100:.2f}\\n\")\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # Early stopping based on validation loss and save best model based on F1\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            \n",
        "        if val_f1 > best_val_f1:\n",
        "            best_val_f1 = val_f1\n",
        "            torch.save(model.state_dict(), 'best_model.pt')\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69CeK2rg5QZU",
        "outputId": "f59f76e5-77a4-4f86-ba1b-402ae32935de"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/12 [Train]: 100%|██████████| 335/335 [00:36<00:00,  9.11it/s, loss=2.82]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1 Train Loss: 2.8173 Acc: 31.54% Precision: 33.48 Recall: 31.54 F1: 31.04\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Val Loss: 4.2210 Val Acc: 2.46% Val Precision: 2.06 Val Recall: 2.46 Val F1: 2.06\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/12 [Train]: 100%|██████████| 335/335 [00:37<00:00,  8.96it/s, loss=2.07]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2 Train Loss: 2.0724 Acc: 49.13% Precision: 49.73 Recall: 49.13 F1: 48.89\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 Val Loss: 4.7374 Val Acc: 2.09% Val Precision: 2.06 Val Recall: 2.09 Val F1: 1.96\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/12 [Train]: 100%|██████████| 335/335 [00:38<00:00,  8.59it/s, loss=1.41]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3 Train Loss: 1.4088 Acc: 65.33% Precision: 65.53 Recall: 65.33 F1: 65.22\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 Val Loss: 5.3310 Val Acc: 2.43% Val Precision: 2.30 Val Recall: 2.43 Val F1: 2.28\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/12 [Train]: 100%|██████████| 335/335 [00:39<00:00,  8.58it/s, loss=0.764]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4 Train Loss: 0.7640 Acc: 84.49% Precision: 84.58 Recall: 84.49 F1: 84.45\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 Val Loss: 5.8305 Val Acc: 2.20% Val Precision: 2.23 Val Recall: 2.20 Val F1: 2.18\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/12 [Train]: 100%|██████████| 335/335 [00:38<00:00,  8.63it/s, loss=0.459]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5 Train Loss: 0.4592 Acc: 92.81% Precision: 92.82 Recall: 92.81 F1: 92.80\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 Val Loss: 6.3506 Val Acc: 2.17% Val Precision: 2.28 Val Recall: 2.17 Val F1: 2.17\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/12 [Train]: 100%|██████████| 335/335 [00:42<00:00,  7.84it/s, loss=0.251]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 6 Train Loss: 0.2508 Acc: 97.73% Precision: 97.74 Recall: 97.73 F1: 97.73\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 Val Loss: 6.9397 Val Acc: 1.98% Val Precision: 2.00 Val Recall: 1.98 Val F1: 1.94\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/12 [Train]: 100%|██████████| 335/335 [00:42<00:00,  7.90it/s, loss=0.106]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 7 Train Loss: 0.1061 Acc: 99.59% Precision: 99.59 Recall: 99.59 F1: 99.59\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 Val Loss: 7.3180 Val Acc: 2.17% Val Precision: 2.24 Val Recall: 2.17 Val F1: 2.15\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/12 [Train]: 100%|██████████| 335/335 [00:41<00:00,  8.09it/s, loss=0.0563]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 8 Train Loss: 0.0563 Acc: 99.92% Precision: 99.92 Recall: 99.92 F1: 99.92\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 Val Loss: 7.7804 Val Acc: 2.13% Val Precision: 2.11 Val Recall: 2.13 Val F1: 2.07\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/12 [Train]: 100%|██████████| 335/335 [00:42<00:00,  7.79it/s, loss=0.0281]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 9 Train Loss: 0.0281 Acc: 99.99% Precision: 99.99 Recall: 99.99 F1: 99.99\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 Val Loss: 8.1676 Val Acc: 2.35% Val Precision: 2.43 Val Recall: 2.35 Val F1: 2.35\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/12 [Train]: 100%|██████████| 335/335 [00:43<00:00,  7.65it/s, loss=0.0157]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 10 Train Loss: 0.0157 Acc: 100.00% Precision: 100.00 Recall: 100.00 F1: 100.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 Val Loss: 8.3042 Val Acc: 2.24% Val Precision: 2.30 Val Recall: 2.24 Val F1: 2.24\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/12 [Train]: 100%|██████████| 335/335 [00:42<00:00,  7.86it/s, loss=0.0124]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 11 Train Loss: 0.0124 Acc: 100.00% Precision: 100.00 Recall: 100.00 F1: 100.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11 Val Loss: 8.4443 Val Acc: 2.35% Val Precision: 2.35 Val Recall: 2.35 Val F1: 2.32\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/12 [Train]: 100%|██████████| 335/335 [00:42<00:00,  7.95it/s, loss=0.0101]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 12 Train Loss: 0.0101 Acc: 100.00% Precision: 100.00 Recall: 100.00 F1: 100.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12 Val Loss: 8.5721 Val Acc: 2.20% Val Precision: 2.22 Val Recall: 2.20 Val F1: 2.19\n",
            "\n"
          ]
        }
      ],
      "source": [
        "train_model_new(model, train_loader, val_loader, criterion, optimizer, device, num_epochs, patience=num_epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Lets Train our model again with the error being solved!!!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "9ssBI2EF8rLT"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/12 [Train]: 100%|██████████| 335/335 [00:44<00:00,  7.58it/s, loss=2.86]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1 Train Loss: 2.8587 Acc: 23.88% Precision: 25.71 Recall: 23.88 F1: 23.00\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Val Loss: 1.8208 Val Acc: 49.70% Val Precision: 54.66 Val Recall: 49.70 Val F1: 46.87\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/12 [Train]: 100%|██████████| 335/335 [00:38<00:00,  8.67it/s, loss=1.5] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2 Train Loss: 1.5027 Acc: 60.14% Precision: 58.63 Recall: 60.14 F1: 58.96\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 Val Loss: 1.3019 Val Acc: 65.53% Val Precision: 67.04 Val Recall: 65.53 Val F1: 64.60\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/12 [Train]: 100%|██████████| 335/335 [00:40<00:00,  8.18it/s, loss=1.22]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3 Train Loss: 1.2159 Acc: 67.82% Precision: 67.52 Recall: 67.82 F1: 67.39\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 Val Loss: 1.1454 Val Acc: 69.42% Val Precision: 70.41 Val Recall: 69.42 Val F1: 68.91\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/12 [Train]: 100%|██████████| 335/335 [00:43<00:00,  7.70it/s, loss=0.97] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4 Train Loss: 0.9704 Acc: 74.18% Precision: 74.16 Recall: 74.18 F1: 73.93\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 Val Loss: 1.0738 Val Acc: 71.21% Val Precision: 73.80 Val Recall: 71.21 Val F1: 71.65\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/12 [Train]: 100%|██████████| 335/335 [00:42<00:00,  7.97it/s, loss=0.874]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5 Train Loss: 0.8744 Acc: 76.05% Precision: 75.91 Recall: 76.05 F1: 75.82\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 Val Loss: 1.0790 Val Acc: 71.62% Val Precision: 73.98 Val Recall: 71.62 Val F1: 71.81\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/12 [Train]: 100%|██████████| 335/335 [00:44<00:00,  7.61it/s, loss=0.802]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 6 Train Loss: 0.8020 Acc: 78.28% Precision: 78.19 Recall: 78.28 F1: 78.09\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 Val Loss: 1.1047 Val Acc: 72.14% Val Precision: 73.66 Val Recall: 72.14 Val F1: 72.26\n",
            "\n",
            "Early stopping at epoch 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "train_model_new(model, train_loader, val_loader, criterion, optimizer, device, num_epochs, patience=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Lets optimise it a bit more\n",
        "**I asked ChatGPT how we can optimise it more, the following are the ways**\n",
        "\n",
        "- Better Learning Rate Scheduling :-\n",
        "\n",
        "Your current scheduler is StepLR — let’s try ReduceLROnPlateau which adapts based on validation loss or F1:\n",
        "```python\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor=0.5, verbose=True)\n",
        "```\n",
        "\n",
        "- Use Weight decay\n",
        "```python \n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
        "```\n",
        "\n",
        "- Add label Smoothing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Label Smoothing Loss\n",
        "class LabelSmoothingLoss(nn.Module):\n",
        "    def __init__(self, classes, smoothing=0.1):\n",
        "        super().__init__()\n",
        "        self.confidence = 1.0 - smoothing\n",
        "        self.smoothing = smoothing\n",
        "        self.classes = classes\n",
        "        self.kl_div = nn.KLDivLoss(reduction='batchmean')\n",
        "\n",
        "    def forward(self, pred, target):\n",
        "        pred = torch.log_softmax(pred, dim=-1)\n",
        "        true_dist = torch.zeros_like(pred).fill_(self.smoothing / (self.classes - 1))\n",
        "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
        "        return self.kl_div(pred, true_dist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Lets change the LR scheduler**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model_optimized(model, train_loader, val_loader, num_classes, device, num_epochs=10, patience=3):\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)\n",
        "\n",
        "    best_val_f1 = 0\n",
        "    patience_counter = 0\n",
        "\n",
        "    history = {\n",
        "        'train_loss': [], 'train_acc': [],\n",
        "        'val_loss': [], 'val_acc': []\n",
        "    }\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # === Train Phase ===\n",
        "        model.train()\n",
        "        train_loss, all_preds, all_labels = 0.0, [], []\n",
        "\n",
        "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
        "        for inputs, labels in loop:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            loop.set_postfix(loss=train_loss/len(all_labels))\n",
        "\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_acc = accuracy_score(all_labels, all_preds)\n",
        "\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "\n",
        "        print(f\"\\nEpoch {epoch+1} Train Loss: {train_loss:.4f} Acc: {train_acc*100:.2f}%\")\n",
        "\n",
        "        # === Validation Phase ===\n",
        "        model.eval()\n",
        "        val_loss, val_preds, val_labels = 0.0, [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            loop = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\", leave=False)\n",
        "            for inputs, labels in loop:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                preds = torch.argmax(outputs, dim=1)\n",
        "                val_preds.extend(preds.cpu().numpy())\n",
        "                val_labels.extend(labels.cpu().numpy())\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        val_acc = accuracy_score(val_labels, val_preds)\n",
        "        val_precision, val_recall, val_f1, _ = precision_recall_fscore_support(\n",
        "            val_labels, val_preds, average='weighted', zero_division=0\n",
        "        )\n",
        "\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch+1} Val Loss: {val_loss:.4f} Acc: {val_acc*100:.2f}% F1: {val_f1*100:.2f}\")\n",
        "\n",
        "        scheduler.step(val_f1)\n",
        "\n",
        "        # Early stopping on validation F1\n",
        "        if val_f1 > best_val_f1:\n",
        "            best_val_f1 = val_f1\n",
        "            torch.save(model.state_dict(), 'best_model.pt')\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    print(f\"\\n✅ Best Val F1: {best_val_f1*100:.2f}\")\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 [Train]: 100%|██████████| 335/335 [01:25<00:00,  3.93it/s, loss=0.595]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1 Train Loss: 0.5952 Acc: 84.30%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Val Loss: 1.0295 Acc: 74.87% F1: 74.89\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 [Train]: 100%|██████████| 335/335 [01:32<00:00,  3.64it/s, loss=0.461]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2 Train Loss: 0.4614 Acc: 87.58%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 Val Loss: 1.0476 Acc: 74.91% F1: 74.88\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 [Train]: 100%|██████████| 335/335 [01:37<00:00,  3.44it/s, loss=0.391]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3 Train Loss: 0.3907 Acc: 89.52%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 Val Loss: 1.0766 Acc: 74.65% F1: 74.62\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 [Train]: 100%|██████████| 335/335 [01:37<00:00,  3.42it/s, loss=0.339]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4 Train Loss: 0.3388 Acc: 90.88%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 Val Loss: 1.1025 Acc: 74.50% F1: 74.67\n",
            "Early stopping at epoch 4\n",
            "\n",
            "✅ Best Val F1: 74.89\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "model_training_1 = train_model_optimized(\n",
        "    model, train_loader, val_loader, num_classes=num_classes,\n",
        "    device=device, num_epochs=10, patience=3\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**The model is overfitting**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_accuracy(train_acc, val_acc):\n",
        "    epochs = range(1, len(train_acc) + 1)\n",
        "    plt.figure(figsize=(8,5))\n",
        "    plt.plot(epochs, train_acc, 'b-', label='Training Accuracy')\n",
        "    plt.plot(epochs, val_acc, 'r-', label='Validation Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_accuracy(\n",
        "    model_training_1['train_acc'], model_training_1['val_acc']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using Label Smoothing and weight decay in optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_model_optimized(model, train_loader, val_loader, num_classes, device, num_epochs=10, patience=3):\n",
        "    criterion = LabelSmoothingLoss(classes=num_classes, smoothing=0.1).to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)\n",
        "\n",
        "    best_val_f1 = 0\n",
        "    patience_counter = 0\n",
        "\n",
        "    history = {\n",
        "        'train_loss': [], 'train_acc': [],\n",
        "        'val_loss': [], 'val_acc': []\n",
        "    }\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # === Train Phase ===\n",
        "        model.train()\n",
        "        train_loss, all_preds, all_labels = 0.0, [], []\n",
        "\n",
        "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n",
        "        for inputs, labels in loop:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            loop.set_postfix(loss=train_loss/len(all_labels))\n",
        "\n",
        "        train_loss /= len(train_loader.dataset)\n",
        "        train_acc = accuracy_score(all_labels, all_preds)\n",
        "\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "\n",
        "        print(f\"\\nEpoch {epoch+1} Train Loss: {train_loss:.4f} Acc: {train_acc*100:.2f}%\")\n",
        "\n",
        "        # === Validation Phase ===\n",
        "        model.eval()\n",
        "        val_loss, val_preds, val_labels = 0.0, [], []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            loop = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\", leave=False)\n",
        "            for inputs, labels in loop:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                preds = torch.argmax(outputs, dim=1)\n",
        "                val_preds.extend(preds.cpu().numpy())\n",
        "                val_labels.extend(labels.cpu().numpy())\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        val_acc = accuracy_score(val_labels, val_preds)\n",
        "        val_precision, val_recall, val_f1, _ = precision_recall_fscore_support(\n",
        "            val_labels, val_preds, average='weighted', zero_division=0\n",
        "        )\n",
        "\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch+1} Val Loss: {val_loss:.4f} Acc: {val_acc*100:.2f}% F1: {val_f1*100:.2f}\")\n",
        "\n",
        "        scheduler.step(val_f1)\n",
        "\n",
        "        # Early stopping on validation F1\n",
        "        if val_f1 > best_val_f1:\n",
        "            best_val_f1 = val_f1\n",
        "            torch.save(model.state_dict(), 'best_model.pt')\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    print(f\"\\n✅ Best Val F1: {best_val_f1*100:.2f}\")\n",
        "    return history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **The model is not overfitting but could not achieve better accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/20 [Train]: 100%|██████████| 335/335 [00:41<00:00,  8.02it/s, loss=1.01]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1 Train Loss: 1.0123 Acc: 68.62%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Val Loss: 1.0608 Acc: 68.37% F1: 68.02\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/20 [Train]: 100%|██████████| 335/335 [00:46<00:00,  7.21it/s, loss=0.935]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2 Train Loss: 0.9351 Acc: 70.79%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 Val Loss: 1.0088 Acc: 68.97% F1: 68.98\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/20 [Train]: 100%|██████████| 335/335 [00:49<00:00,  6.81it/s, loss=0.88] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3 Train Loss: 0.8802 Acc: 72.31%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 Val Loss: 1.0024 Acc: 68.89% F1: 69.37\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/20 [Train]: 100%|██████████| 335/335 [00:54<00:00,  6.10it/s, loss=0.842]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4 Train Loss: 0.8424 Acc: 72.92%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 Val Loss: 0.9912 Acc: 69.42% F1: 68.90\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/20 [Train]: 100%|██████████| 335/335 [00:59<00:00,  5.61it/s, loss=0.827]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5 Train Loss: 0.8273 Acc: 73.45%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 Val Loss: 1.0275 Acc: 67.59% F1: 67.77\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/20 [Train]: 100%|██████████| 335/335 [01:02<00:00,  5.34it/s, loss=0.795]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 6 Train Loss: 0.7946 Acc: 74.45%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 Val Loss: 0.9965 Acc: 70.28% F1: 70.73\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/20 [Train]: 100%|██████████| 335/335 [01:05<00:00,  5.14it/s, loss=0.757]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 7 Train Loss: 0.7573 Acc: 75.61%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 Val Loss: 1.0153 Acc: 68.78% F1: 69.14\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/20 [Train]: 100%|██████████| 335/335 [01:12<00:00,  4.60it/s, loss=0.746]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 8 Train Loss: 0.7464 Acc: 75.41%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 Val Loss: 1.0065 Acc: 69.72% F1: 69.72\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/20 [Train]: 100%|██████████| 335/335 [01:16<00:00,  4.38it/s, loss=0.729]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 9 Train Loss: 0.7286 Acc: 76.46%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                 \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 Val Loss: 0.9286 Acc: 71.32% F1: 71.37\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/20 [Train]: 100%|██████████| 335/335 [01:22<00:00,  4.08it/s, loss=0.723]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 10 Train Loss: 0.7226 Acc: 76.35%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                  \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 Val Loss: 0.9827 Acc: 69.75% F1: 69.47\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 11/20 [Train]: 100%|██████████| 335/335 [01:23<00:00,  4.03it/s, loss=0.69] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 11 Train Loss: 0.6898 Acc: 77.23%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                  \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11 Val Loss: 0.9443 Acc: 71.25% F1: 70.80\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 12/20 [Train]: 100%|██████████| 335/335 [01:31<00:00,  3.67it/s, loss=0.68] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 12 Train Loss: 0.6802 Acc: 77.65%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12 Val Loss: 0.9479 Acc: 70.13% F1: 70.38\n",
            "Early stopping at epoch 12\n",
            "\n",
            "✅ Best Val F1: 71.37\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r"
          ]
        }
      ],
      "source": [
        "model_training = train_model_optimized(\n",
        "    model, train_loader, val_loader, num_classes=num_classes,\n",
        "    device=device, num_epochs=20, patience=3\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
